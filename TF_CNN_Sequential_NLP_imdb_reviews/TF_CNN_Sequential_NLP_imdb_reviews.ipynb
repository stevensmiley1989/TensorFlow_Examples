{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF_CNN_Sequential_NLP_imdb_reviews.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLNmbNWawmZZ"
      },
      "source": [
        "# 1.0 Purpose\n",
        "The purpose of this notebook is to use Embedding for a Natural Language Processing (NLP) task with TensorFlow on the imbd_reviews dataset.  Predictions are \"1\" for a bad review and \"0\" for  a good review."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcR7-l_Dw09x"
      },
      "source": [
        "# 2.0 Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6y0wNF9cYgp"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import tensorflow_datasets as tfds\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4k4ixhbA5rd3"
      },
      "source": [
        "## Helper Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEScNl4x2LqS"
      },
      "source": [
        "### decode_review"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_pqMppSgBDm"
      },
      "source": [
        "def decode_review(text):\n",
        "    return ' '.join([reverse_word_index.get(i, '?') for i in text])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ui35OFgL2PXd"
      },
      "source": [
        "### get_training_metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZtREbov1mqD"
      },
      "source": [
        "def get_training_metrics(history):\n",
        "  \n",
        "  # This is needed depending on if you used the pretrained model or you trained it yourself\n",
        "  if not isinstance(history, pd.core.frame.DataFrame):\n",
        "    history = history.history\n",
        "  \n",
        "  acc = history['binary_accuracy']\n",
        "  val_acc = history['val_binary_accuracy']\n",
        "\n",
        "  loss = history['loss']\n",
        "  val_loss = history['val_loss']\n",
        "\n",
        "  return acc, val_acc, loss, val_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oeJ5Jd_M2b6n"
      },
      "source": [
        "### plot_train_eval"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTbiFeyJ2VCr"
      },
      "source": [
        "def plot_train_eval(history,name='',parameters='',optimizer_name='',loss='',accuracy_metric='',epochs='',vocab_size='',embedding_dim='',max_length='',trunc_type='',oov_tok=''):\n",
        "  acc, val_acc, loss_values, val_loss = get_training_metrics(history)\n",
        "\n",
        "  acc_plot = pd.DataFrame({\"training accuracy\":acc, \"evaluation accuracy\":val_acc})\n",
        "  acc_plot = sns.lineplot(data=acc_plot)\n",
        "  acc_plot.set_title(f'training vs evaluation accuracy: {name} \\n # parameters={parameters} \\n optimizer_name={optimizer_name} \\n loss={loss} \\n accuracy_metric={accuracy_metric} \\n epochs={epochs} \\n vocab_size={vocab_size} \\n embedding_dim={embedding_dim} \\n max_length={max_length} \\n trunc_type={trunc_type} \\n oov_tok={oov_tok}')\n",
        "  acc_plot.set_xlabel('epoch')\n",
        "  acc_plot.set_ylabel(accuracy_metric)\n",
        "  plt.savefig(f'{name} - train_acc_vs_eval_acc.jpg',bbox_inches='tight')\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "  print(\"\")\n",
        "\n",
        "  loss_plot = pd.DataFrame({\"training loss\":loss_values, \"evaluation loss\":val_loss})\n",
        "  loss_plot = sns.lineplot(data=loss_plot)\n",
        "  loss_plot.set_title(f'training vs evaluation loss: {name} \\n # parameters={parameters} \\n optimizer_name={optimizer_name}  \\n loss={loss} \\naccuracy_metric={accuracy_metric} \\n epochs={epochs} \\n vocab_size={vocab_size} \\n embedding_dim={embedding_dim} \\n max_length={max_length} \\n trunc_type={trunc_type} \\n oov_tok={oov_tok}')\n",
        "  loss_plot.set_xlabel('epoch')\n",
        "  loss_plot.set_ylabel(loss)\n",
        "  plt.savefig(f'{name} - train_loss_vs_eval_loss.jpg',bbox_inches='tight')\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U12-cl_b7GaS"
      },
      "source": [
        "### model_picker"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcEjNngH6QKK"
      },
      "source": [
        "def model_picker(vocab_size=100,embedding_dim=16,input_length=100,model_name='model1'):\n",
        "\n",
        "  if model_name=='model1':\n",
        "    model = tf.keras.Sequential([\n",
        "                                tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "                                tf.keras.layers.Flatten(),\n",
        "                                tf.keras.layers.Dense(6,activation='relu'),\n",
        "                                tf.keras.layers.Dense(1,activation='sigmoid')\n",
        "    ])\n",
        "    model_description=f'Embedding(vocab_size={vocab_size}, \\n embedding_dim={embedding_dim}, \\n input_length={max_length}), \\n Flatten, \\n Dense(6,relu), \\n Dense(1,sigmoid)'\n",
        "  elif model_name=='model2':\n",
        "    model = tf.keras.Sequential([\n",
        "                                tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "                                tf.keras.layers.GlobalAveragePooling1D(),\n",
        "                                tf.keras.layers.Dense(6,activation='relu'),\n",
        "                                tf.keras.layers.Dense(1,activation='sigmoid')\n",
        "    ])\n",
        "    model_description=f'Embedding(vocab_size={vocab_size},embedding_dim={embedding_dim},input_length={max_length}), \\n GlobalAveragePooling1D,\\n Dense(6,relu), \\n Dense(1,sigmoid)'\n",
        "  elif model_name=='model3':\n",
        "    model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "    model_description=f'Embedding(vocab_size={vocab_size}, \\n embedding_dim={embedding_dim}), \\n Bidirectional(LSTM(64,return_sequences=True)), \\n Bidirectional(LSTM(32)), \\n Dense(64,relu), \\n Dense(1,sigmoid)'\n",
        "  elif model_name=='model4':\n",
        "    model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "    tf.keras.layers.Dense(24, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "    model_description=f'Embedding(vocab_size={vocab_size}, \\n embedding_dim={embedding_dim}), \\n Bidirectional(LSTM(32)), \\n Dense(24,relu), \\n Dense(1,sigmoid)'\n",
        "  elif model_name=='model5':\n",
        "    model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "    tf.keras.layers.Dense(6, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "    model_description=f'Embedding(vocab_size={vocab_size},embedding_dim={embedding_dim},input_length={max_length}), \\n Bidirectional(LSTM(32)),Dense(6,relu),Dense(1,sigmoid)'\n",
        "  elif model_name=='model6':\n",
        "    model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "  tf.keras.layers.Conv1D(128, 5, activation='relu'),\n",
        "  tf.keras.layers.GlobalAveragePooling1D(),\n",
        "  tf.keras.layers.Dense(6, activation='relu'),\n",
        "  tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "    model_description=f'Embedding(vocab_size={vocab_size},embedding_dim={embedding_dim},input_length={max_length}), \\n Conv1D(128,5,activation=relu), \\n GlobalAveragePooling1D, \\n Dense(6,relu),Dense(1,sigmoid)'\n",
        "  elif model_name=='model7':\n",
        "    model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.GRU(32)),\n",
        "    tf.keras.layers.Dense(6, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "    model_description=f'Embedding(vocab_size={vocab_size},embedding_dim={embedding_dim},input_length={max_length}), \\n Bidirectional(GRU(32)),Dense(6,relu),Dense(1,sigmoid)'\n",
        "  return model,model_description"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7CODBZ6w4Gg"
      },
      "source": [
        "# 3.0 Import **imbd_reviews**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfqvO9PGkWvy"
      },
      "source": [
        "https://www.tensorflow.org/datasets/catalog/imdb_reviews"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SswhRRRWccPt"
      },
      "source": [
        "\n",
        "imdb, info = tfds.load(\"imdb_reviews\", with_info=True, as_supervised=True,download=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyppt0CJ2plx"
      },
      "source": [
        "cols=['filename','model_name','model_description',\n",
        "      'optimizer',\n",
        "      'loss',\n",
        "      'accuracy_metric','epochs','vocab_size','embedding_dim','max_length','trunc_type','oov_tok','final_eval_loss','final_eval_acc']\n",
        "df_metrics=pd.DataFrame(columns=cols)\n",
        "df_metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPDaSoerw9Ua"
      },
      "source": [
        "# 4.1 model1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVxSAgiYy1Rr"
      },
      "source": [
        "## Set Embedding/Modeling Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tnt1QscXfnvK"
      },
      "source": [
        "filename='TF_CNN_Sequential_NLP_imdb_reviews.ipynb'\n",
        "model_name='model1'\n",
        "optimizer='adam'\n",
        "optimizer_name=str(optimizer)\n",
        "loss='binary_crossentropy'\n",
        "accuracy_metric='binary_accuracy'\n",
        "epochs=10\n",
        "\n",
        "vocab_size = 10000\n",
        "embedding_dim = 16\n",
        "max_length = 120\n",
        "trunc_type='post'\n",
        "oov_tok = '<OOV>'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uC5GIpB-CZHv"
      },
      "source": [
        "## Split Train/Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4mHHDs3cyu7"
      },
      "source": [
        "train_data, test_data = imdb['train'], imdb['test']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwBZzrNnfc5B"
      },
      "source": [
        "training_sentences = []\n",
        "training_labels = []\n",
        "\n",
        "testing_sentences = []\n",
        "testing_labels = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BFhuEW3ffTx"
      },
      "source": [
        "for s, l in train_data:\n",
        "  training_sentences.append(str(s.numpy()))\n",
        "  training_labels.append(l.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7jCR1k6fhZg"
      },
      "source": [
        "for s, l in test_data:\n",
        "  testing_sentences.append(str(s.numpy()))\n",
        "  testing_labels.append(l.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HW2TCqlflwd"
      },
      "source": [
        "import numpy as np\n",
        "training_labels_final = np.array(training_labels)\n",
        "testing_labels_final = np.array(testing_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "623CjvbKy6Gq"
      },
      "source": [
        "## Create Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iw8lT9GFc5OV"
      },
      "source": [
        "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok) #create tokenizer that has a vocab_size & oov_token specified above"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bb6j7Ae8c669"
      },
      "source": [
        "testing_labels_final.max() #ensure max is still 1 for a \"bad\" review"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gl8jg-SLf3cN"
      },
      "source": [
        "tokenizer.fit_on_texts(training_sentences) #fit the tokenizer on the training_sentences "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19U3LozGxWph"
      },
      "source": [
        "word_index = tokenizer.word_index #get the word index for the tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkwtWEl5xafa"
      },
      "source": [
        "sequences = tokenizer.texts_to_sequences(training_sentences) #convert texts to sequences using the tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAqEeo2af5Di"
      },
      "source": [
        "padded = pad_sequences(sequences, maxlen=max_length, truncating=trunc_type) # pad the sequences by the max_length with truncation set to trunc_type"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmBnxQqYxzBp"
      },
      "source": [
        "testing_sequences = tokenizer.texts_to_sequences(testing_sentences) # convert the testing_sentences to testing_sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiuQKvoMf_yd"
      },
      "source": [
        "testing_padded = pad_sequences(testing_sequences, maxlen=max_length) # convert the testing_sequences to testing_padded"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtiZvpCxyIO2"
      },
      "source": [
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()]) # reverse the key,value from word_index to check index value to key"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpZMCzq_DFwb"
      },
      "source": [
        "print(decode_review(padded[0])) #This is after it has been padded and OOV in place, but decoded.  Recall this is actually padded as a sequence of numbers for training\n",
        "print(training_sentences[0]) #This is the original"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XgIOO-Jz1_P"
      },
      "source": [
        "## Create Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9w-whECxgNXd"
      },
      "source": [
        "model,model_description=model_picker(vocab_size=vocab_size,embedding_dim=embedding_dim,input_length=max_length,model_name='model1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6o1ai-Hk7_V"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kVBajeAk-aH"
      },
      "source": [
        "model.compile(loss=loss,optimizer=optimizer,metrics=[accuracy_metric])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdFKvDgP0O9U"
      },
      "source": [
        "## Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLpCqiZ_lA-n"
      },
      "source": [
        "history=model.fit(padded, training_labels_final,epochs=epochs,validation_data=(testing_padded,\n",
        "                                                                           testing_labels_final))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tg-CNEsD0UWk"
      },
      "source": [
        "## Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8N3OhMZlFTE"
      },
      "source": [
        "e = model.layers[0]\n",
        "weights=e.get_weights()[0]\n",
        "print(weights.shape) # shape: (vocab_size, embedding_dim)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykh7ySMh-3Ux"
      },
      "source": [
        "final_eval_loss,final_eval_acc=model.evaluate(testing_padded,testing_labels_final)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLlVGlms__5L"
      },
      "source": [
        "final_eval_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAmBjzYc2BZl"
      },
      "source": [
        "trainableParams = np.sum([np.prod(v.get_shape()) for v in model.trainable_weights])\n",
        "trainableParams"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USQTrKfn2FXe"
      },
      "source": [
        "plot_train_eval(history,model_name,trainableParams,optimizer_name,loss,accuracy_metric,epochs,vocab_size,embedding_dim,max_length,trunc_type,oov_tok)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtcHyUnE99Vj"
      },
      "source": [
        "df=pd.DataFrame([[filename,model_name,model_description,optimizer,loss,accuracy_metric,epochs,vocab_size,embedding_dim,max_length,trunc_type,oov_tok,final_eval_loss,final_eval_acc]],columns=cols)\n",
        "df_metrics=df_metrics.append(df,ignore_index=True)\n",
        "df_metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIuJl9gEAfgL"
      },
      "source": [
        "model.save(model_name) #save model\n",
        "model=tf.keras.models.load_model(model_name) #load model\n",
        "df_metrics.to_excel('df_metrics.xlsx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUj68SuPlfgN"
      },
      "source": [
        "import io\n",
        "\n",
        "out_v = io.open(f'vecs_{model_name}.tsv', 'w', encoding='utf-8')\n",
        "out_m = io.open(f'meta_{model_name}.tsv', 'w', encoding='utf-8')\n",
        "for word_num in range(1, vocab_size):\n",
        "  word = reverse_word_index[word_num]\n",
        "  embeddings = weights[word_num]\n",
        "  out_m.write(word + \"\\n\")\n",
        "  out_v.write('\\t'.join([str(x) for x in embeddings]) + \"\\n\")\n",
        "out_v.close()\n",
        "out_m.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tc8QvtGDlhuK"
      },
      "source": [
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "  pass\n",
        "else:\n",
        "  files.download(f'vecs_{model_name}.tsv')\n",
        "  files.download(f'meta_{model_name}.tsv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPksXcQUm5Yd"
      },
      "source": [
        "# Testing new Custom Reviews\n",
        "sentence1='What a great movie.'\n",
        "test1=tokenizer.texts_to_sequences([sentence1])\n",
        "test1= pad_sequences(test1, maxlen=max_length, truncating=trunc_type)\n",
        "answer=model.predict(test1)\n",
        "print(f'Review for this sentence: \\n {sentence1} \\n is a value of {answer}')\n",
        "print('This makes sense since it is a value close to 1, meaning a good review')\n",
        "print('\\n')\n",
        "\n",
        "sentence2='What a terrible movie.'\n",
        "test2=tokenizer.texts_to_sequences([sentence2])\n",
        "test2= pad_sequences(test2, maxlen=max_length, truncating=trunc_type)\n",
        "answer=model.predict(test2)\n",
        "print(f'Review for this sentence: \\n {sentence2} \\n is a value of {answer}')\n",
        "print('This makes sense since it is a value close to 0, meaning a bad review')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQ5oj7HcC4Fm"
      },
      "source": [
        "# 4.2 model2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8y1q-c3tC4Fn"
      },
      "source": [
        "## Set Embedding/Modeling Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kX-jmW75C4Fn"
      },
      "source": [
        "filename='TF_CNN_Sequential_NLP_imdb_reviews.ipynb'\n",
        "model_name='model2'\n",
        "optimizer='adam'\n",
        "optimizer_name=str(optimizer)\n",
        "loss='binary_crossentropy'\n",
        "accuracy_metric='binary_accuracy'\n",
        "epochs=10\n",
        "\n",
        "vocab_size = 10000\n",
        "embedding_dim = 16\n",
        "max_length = 120\n",
        "trunc_type='post'\n",
        "oov_tok = '<OOV>'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWqsgHsAC4Fn"
      },
      "source": [
        "## Split Train/Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2l94hxELC4Fo"
      },
      "source": [
        "train_data, test_data = imdb['train'], imdb['test']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imoVa5OxC4Fo"
      },
      "source": [
        "training_sentences = []\n",
        "training_labels = []\n",
        "\n",
        "testing_sentences = []\n",
        "testing_labels = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62SSNZxBC4Fp"
      },
      "source": [
        "for s, l in train_data:\n",
        "  training_sentences.append(str(s.numpy()))\n",
        "  training_labels.append(l.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syuRyxRFC4Fp"
      },
      "source": [
        "for s, l in test_data:\n",
        "  testing_sentences.append(str(s.numpy()))\n",
        "  testing_labels.append(l.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFYKLxRyC4Fp"
      },
      "source": [
        "import numpy as np\n",
        "training_labels_final = np.array(training_labels)\n",
        "testing_labels_final = np.array(testing_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rqDKNa-C4Fp"
      },
      "source": [
        "## Create Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UT8lHRauC4Fp"
      },
      "source": [
        "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok) #create tokenizer that has a vocab_size & oov_token specified above"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0ToLQ4EC4Fq"
      },
      "source": [
        "testing_labels_final.max() #ensure max is still 1 for a \"bad\" review"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYQVMLXZC4Fq"
      },
      "source": [
        "tokenizer.fit_on_texts(training_sentences) #fit the tokenizer on the training_sentences "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-Qg1hYKC4Fq"
      },
      "source": [
        "word_index = tokenizer.word_index #get the word index for the tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3PcgtmIC4Fq"
      },
      "source": [
        "sequences = tokenizer.texts_to_sequences(training_sentences) #convert texts to sequences using the tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eeedPArwC4Fr"
      },
      "source": [
        "padded = pad_sequences(sequences, maxlen=max_length, truncating=trunc_type) # pad the sequences by the max_length with truncation set to trunc_type"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sPu9ALVC4Fs"
      },
      "source": [
        "testing_sequences = tokenizer.texts_to_sequences(testing_sentences) # convert the testing_sentences to testing_sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NV6P0gRSC4Ft"
      },
      "source": [
        "testing_padded = pad_sequences(testing_sequences, maxlen=max_length) # convert the testing_sequences to testing_padded"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59UYH8HhC4Ft"
      },
      "source": [
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()]) # reverse the key,value from word_index to check index value to key"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyRJyLYTDIBa"
      },
      "source": [
        "print(decode_review(padded[0])) #This is after it has been padded and OOV in place, but decoded.  Recall this is actually padded as a sequence of numbers for training\n",
        "print(training_sentences[0]) #This is the original"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqKmgggMC4Ft"
      },
      "source": [
        "## Create Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNGs5K_dC4Fu"
      },
      "source": [
        "model,model_description=model_picker(vocab_size=vocab_size,embedding_dim=embedding_dim,input_length=max_length,model_name='model1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9zvtdO4C4Fu"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNLGTTIWC4Fu"
      },
      "source": [
        "model.compile(loss=loss,optimizer=optimizer,metrics=[accuracy_metric])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5kts9r1C4Fu"
      },
      "source": [
        "## Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYqFUDgaC4Fv"
      },
      "source": [
        "history=model.fit(padded, training_labels_final,epochs=epochs,validation_data=(testing_padded,\n",
        "                                                                           testing_labels_final))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DkULKtHQC4Fv"
      },
      "source": [
        "## Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jh5B-1sqC4Fv"
      },
      "source": [
        "e = model.layers[0]\n",
        "weights=e.get_weights()[0]\n",
        "print(weights.shape) # shape: (vocab_size, embedding_dim)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5PEgEcNC4Fw"
      },
      "source": [
        "final_eval_loss,final_eval_acc=model.evaluate(testing_padded,testing_labels_final)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMsdE9ivC4Fw"
      },
      "source": [
        "final_eval_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBHMhoFyC4Fw"
      },
      "source": [
        "trainableParams = np.sum([np.prod(v.get_shape()) for v in model.trainable_weights])\n",
        "trainableParams"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZ5EiHCtC4Fw"
      },
      "source": [
        "plot_train_eval(history,model_name,trainableParams,optimizer_name,loss,accuracy_metric,epochs,vocab_size,embedding_dim,max_length,trunc_type,oov_tok)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZFVqiDMC4Fx"
      },
      "source": [
        "df=pd.DataFrame([[filename,model_name,model_description,optimizer,loss,accuracy_metric,epochs,vocab_size,embedding_dim,max_length,trunc_type,oov_tok,final_eval_loss,final_eval_acc]],columns=cols)\n",
        "df_metrics=df_metrics.append(df,ignore_index=True)\n",
        "df_metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvMOMQI8C4Fx"
      },
      "source": [
        "model.save(model_name) #save model\n",
        "model=tf.keras.models.load_model(model_name) #load model\n",
        "df_metrics.to_excel('df_metrics.xlsx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37y_Q0dcC4Fy"
      },
      "source": [
        "import io\n",
        "\n",
        "out_v = io.open(f'vecs_{model_name}.tsv', 'w', encoding='utf-8')\n",
        "out_m = io.open(f'meta_{model_name}.tsv', 'w', encoding='utf-8')\n",
        "for word_num in range(1, vocab_size):\n",
        "  word = reverse_word_index[word_num]\n",
        "  embeddings = weights[word_num]\n",
        "  out_m.write(word + \"\\n\")\n",
        "  out_v.write('\\t'.join([str(x) for x in embeddings]) + \"\\n\")\n",
        "out_v.close()\n",
        "out_m.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibC9dIKAC4Fz"
      },
      "source": [
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "  pass\n",
        "else:\n",
        "  files.download(f'vecs_{model_name}.tsv')\n",
        "  files.download(f'meta_{model_name}.tsv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfhiqqJiC4Fz"
      },
      "source": [
        "# Testing new Custom Reviews\n",
        "sentence1='What a great movie.'\n",
        "test1=tokenizer.texts_to_sequences([sentence1])\n",
        "test1= pad_sequences(test1, maxlen=max_length, truncating=trunc_type)\n",
        "answer=model.predict(test1)\n",
        "print(f'Review for this sentence: \\n {sentence1} \\n is a value of {answer}')\n",
        "print('This makes sense since it is a value close to 1, meaning a good review')\n",
        "print('\\n')\n",
        "\n",
        "sentence2='What a terrible movie.'\n",
        "test2=tokenizer.texts_to_sequences([sentence2])\n",
        "test2= pad_sequences(test2, maxlen=max_length, truncating=trunc_type)\n",
        "answer=model.predict(test2)\n",
        "print(f'Review for this sentence: \\n {sentence2} \\n is a value of {answer}')\n",
        "print('This makes sense since it is a value close to 0, meaning a bad review')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSMgSDE0FoKQ"
      },
      "source": [
        "# 4.3 model3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RaSsOpWHFoKR"
      },
      "source": [
        "## Set Embedding/Modeling Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFdgC7CPFoKS"
      },
      "source": [
        "filename='TF_CNN_Sequential_NLP_imdb_reviews.ipynb'\n",
        "model_name='model3'\n",
        "optimizer='adam'\n",
        "optimizer_name=str(optimizer)\n",
        "loss='binary_crossentropy'\n",
        "accuracy_metric='binary_accuracy'\n",
        "epochs=10\n",
        "\n",
        "vocab_size = 10000\n",
        "embedding_dim = 16\n",
        "max_length = 120\n",
        "trunc_type='post'\n",
        "oov_tok = '<OOV>'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMqhrL0zFoKT"
      },
      "source": [
        "## Split Train/Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wc5AebFMFoKU"
      },
      "source": [
        "train_data, test_data = imdb['train'], imdb['test']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0xLxti7FoKU"
      },
      "source": [
        "training_sentences = []\n",
        "training_labels = []\n",
        "\n",
        "testing_sentences = []\n",
        "testing_labels = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3VMk28VFoKV"
      },
      "source": [
        "for s, l in train_data:\n",
        "  training_sentences.append(str(s.numpy()))\n",
        "  training_labels.append(l.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MEkUca8kFoKW"
      },
      "source": [
        "for s, l in test_data:\n",
        "  testing_sentences.append(str(s.numpy()))\n",
        "  testing_labels.append(l.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNafSGFkFoKX"
      },
      "source": [
        "import numpy as np\n",
        "training_labels_final = np.array(training_labels)\n",
        "testing_labels_final = np.array(testing_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7IRbncadFoKX"
      },
      "source": [
        "## Create Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_AvT6m8FoKZ"
      },
      "source": [
        "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok) #create tokenizer that has a vocab_size & oov_token specified above"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uo3W0Z2_FoKb"
      },
      "source": [
        "testing_labels_final.max() #ensure max is still 1 for a \"bad\" review"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qx7Z978WFoKb"
      },
      "source": [
        "tokenizer.fit_on_texts(training_sentences) #fit the tokenizer on the training_sentences "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGIWUMnUFoKc"
      },
      "source": [
        "word_index = tokenizer.word_index #get the word index for the tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XP77CbYFoKf"
      },
      "source": [
        "sequences = tokenizer.texts_to_sequences(training_sentences) #convert texts to sequences using the tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUOnEdQNFoKf"
      },
      "source": [
        "padded = pad_sequences(sequences, maxlen=max_length, truncating=trunc_type) # pad the sequences by the max_length with truncation set to trunc_type"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ak4T6IS8FoKg"
      },
      "source": [
        "testing_sequences = tokenizer.texts_to_sequences(testing_sentences) # convert the testing_sentences to testing_sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riUjkCTTFoKh"
      },
      "source": [
        "testing_padded = pad_sequences(testing_sequences, maxlen=max_length) # convert the testing_sequences to testing_padded"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxzQGx-AFoKh"
      },
      "source": [
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()]) # reverse the key,value from word_index to check index value to key"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8tF_yRHFoKh"
      },
      "source": [
        "print(decode_review(padded[0])) #This is after it has been padded and OOV in place, but decoded.  Recall this is actually padded as a sequence of numbers for training\n",
        "print(training_sentences[0]) #This is the original"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfHuuG9MFoKj"
      },
      "source": [
        "## Create Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7vMkpyJFoKj"
      },
      "source": [
        "model,model_description=model_picker(vocab_size=vocab_size,embedding_dim=embedding_dim,input_length=max_length,model_name='model1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWFjUNWhFoKk"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3Vzroj7FoKk"
      },
      "source": [
        "model.compile(loss=loss,optimizer=optimizer,metrics=[accuracy_metric])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJSc_OipFoKl"
      },
      "source": [
        "## Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3hpg1Y2FoKm"
      },
      "source": [
        "history=model.fit(padded, training_labels_final,epochs=epochs,validation_data=(testing_padded,\n",
        "                                                                           testing_labels_final))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8SVNbztFoKm"
      },
      "source": [
        "## Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVzBWw9UFoKn"
      },
      "source": [
        "e = model.layers[0]\n",
        "weights=e.get_weights()[0]\n",
        "print(weights.shape) # shape: (vocab_size, embedding_dim)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ED-TtnDhFoKo"
      },
      "source": [
        "final_eval_loss,final_eval_acc=model.evaluate(testing_padded,testing_labels_final)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnbauW0CFoKp"
      },
      "source": [
        "final_eval_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eo-CfCEpFoKp"
      },
      "source": [
        "trainableParams = np.sum([np.prod(v.get_shape()) for v in model.trainable_weights])\n",
        "trainableParams"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxRCa4LwFoKq"
      },
      "source": [
        "plot_train_eval(history,model_name,trainableParams,optimizer_name,loss,accuracy_metric,epochs,vocab_size,embedding_dim,max_length,trunc_type,oov_tok)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26h4t2KfFoKs"
      },
      "source": [
        "df=pd.DataFrame([[filename,model_name,model_description,optimizer,loss,accuracy_metric,epochs,vocab_size,embedding_dim,max_length,trunc_type,oov_tok,final_eval_loss,final_eval_acc]],columns=cols)\n",
        "df_metrics=df_metrics.append(df,ignore_index=True)\n",
        "df_metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuzAc9qiFoKu"
      },
      "source": [
        "model.save(model_name) #save model\n",
        "model=tf.keras.models.load_model(model_name) #load model\n",
        "df_metrics.to_excel('df_metrics.xlsx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Scq3Bd96FoKu"
      },
      "source": [
        "import io\n",
        "\n",
        "out_v = io.open(f'vecs_{model_name}.tsv', 'w', encoding='utf-8')\n",
        "out_m = io.open(f'meta_{model_name}.tsv', 'w', encoding='utf-8')\n",
        "for word_num in range(1, vocab_size):\n",
        "  word = reverse_word_index[word_num]\n",
        "  embeddings = weights[word_num]\n",
        "  out_m.write(word + \"\\n\")\n",
        "  out_v.write('\\t'.join([str(x) for x in embeddings]) + \"\\n\")\n",
        "out_v.close()\n",
        "out_m.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKac-RWCFoKv"
      },
      "source": [
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "  pass\n",
        "else:\n",
        "  files.download(f'vecs_{model_name}.tsv')\n",
        "  files.download(f'meta_{model_name}.tsv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uog78gVUFoKw"
      },
      "source": [
        "# Testing new Custom Reviews\n",
        "sentence1='What a great movie.'\n",
        "test1=tokenizer.texts_to_sequences([sentence1])\n",
        "test1= pad_sequences(test1, maxlen=max_length, truncating=trunc_type)\n",
        "answer=model.predict(test1)\n",
        "print(f'Review for this sentence: \\n {sentence1} \\n is a value of {answer}')\n",
        "print('This makes sense since it is a value close to 1, meaning a good review')\n",
        "print('\\n')\n",
        "\n",
        "sentence2='What a terrible movie.'\n",
        "test2=tokenizer.texts_to_sequences([sentence2])\n",
        "test2= pad_sequences(test2, maxlen=max_length, truncating=trunc_type)\n",
        "answer=model.predict(test2)\n",
        "print(f'Review for this sentence: \\n {sentence2} \\n is a value of {answer}')\n",
        "print('This makes sense since it is a value close to 0, meaning a bad review')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqvnHDkSGiR9"
      },
      "source": [
        "# 4.4 model4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPYtyGWuGiR-"
      },
      "source": [
        "## Set Embedding/Modeling Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "df8La7_bGiR-"
      },
      "source": [
        "filename='TF_CNN_Sequential_NLP_imdb_reviews.ipynb'\n",
        "model_name='model4'\n",
        "optimizer='adam'\n",
        "optimizer_name=str(optimizer)\n",
        "loss='binary_crossentropy'\n",
        "accuracy_metric='binary_accuracy'\n",
        "epochs=10\n",
        "\n",
        "vocab_size = 10000\n",
        "embedding_dim = 16\n",
        "max_length = 120\n",
        "trunc_type='post'\n",
        "oov_tok = '<OOV>'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzhrIX3sGiR_"
      },
      "source": [
        "## Split Train/Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bH1cWlKXGiSA"
      },
      "source": [
        "train_data, test_data = imdb['train'], imdb['test']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdBpOxU7GiSC"
      },
      "source": [
        "training_sentences = []\n",
        "training_labels = []\n",
        "\n",
        "testing_sentences = []\n",
        "testing_labels = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2GfKgQUGiSC"
      },
      "source": [
        "for s, l in train_data:\n",
        "  training_sentences.append(str(s.numpy()))\n",
        "  training_labels.append(l.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-2QFD_TGiSE"
      },
      "source": [
        "for s, l in test_data:\n",
        "  testing_sentences.append(str(s.numpy()))\n",
        "  testing_labels.append(l.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gCV31GCGiSE"
      },
      "source": [
        "import numpy as np\n",
        "training_labels_final = np.array(training_labels)\n",
        "testing_labels_final = np.array(testing_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaiGj9OWGiSG"
      },
      "source": [
        "## Create Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MD2OXGOwGiSH"
      },
      "source": [
        "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok) #create tokenizer that has a vocab_size & oov_token specified above"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-1LL-hKGiSJ"
      },
      "source": [
        "testing_labels_final.max() #ensure max is still 1 for a \"bad\" review"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rggBqLzbGiSL"
      },
      "source": [
        "tokenizer.fit_on_texts(training_sentences) #fit the tokenizer on the training_sentences "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veddMobSGiSM"
      },
      "source": [
        "word_index = tokenizer.word_index #get the word index for the tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Ir1jmH-GiSM"
      },
      "source": [
        "sequences = tokenizer.texts_to_sequences(training_sentences) #convert texts to sequences using the tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cuxRhB8sGiSN"
      },
      "source": [
        "padded = pad_sequences(sequences, maxlen=max_length, truncating=trunc_type) # pad the sequences by the max_length with truncation set to trunc_type"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DpEFe9ccGiSO"
      },
      "source": [
        "testing_sequences = tokenizer.texts_to_sequences(testing_sentences) # convert the testing_sentences to testing_sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Om7hWKU_GiSP"
      },
      "source": [
        "testing_padded = pad_sequences(testing_sequences, maxlen=max_length) # convert the testing_sequences to testing_padded"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bO1bs4Y7GiSP"
      },
      "source": [
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()]) # reverse the key,value from word_index to check index value to key"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-v1FkiGGiSQ"
      },
      "source": [
        "print(decode_review(padded[0])) #This is after it has been padded and OOV in place, but decoded.  Recall this is actually padded as a sequence of numbers for training\n",
        "print(training_sentences[0]) #This is the original"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8EvqLNBGiSQ"
      },
      "source": [
        "## Create Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClhZ1uU6GiSQ"
      },
      "source": [
        "model,model_description=model_picker(vocab_size=vocab_size,embedding_dim=embedding_dim,input_length=max_length,model_name='model1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2HZI2szGiSR"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1kIMbnNGiSR"
      },
      "source": [
        "model.compile(loss=loss,optimizer=optimizer,metrics=[accuracy_metric])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nxvAzQeGiSS"
      },
      "source": [
        "## Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2ALaq6qGiST"
      },
      "source": [
        "history=model.fit(padded, training_labels_final,epochs=epochs,validation_data=(testing_padded,\n",
        "                                                                           testing_labels_final))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DoEOno8lGiST"
      },
      "source": [
        "## Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SawlR5kzGiST"
      },
      "source": [
        "e = model.layers[0]\n",
        "weights=e.get_weights()[0]\n",
        "print(weights.shape) # shape: (vocab_size, embedding_dim)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFs1j0MYGiSU"
      },
      "source": [
        "final_eval_loss,final_eval_acc=model.evaluate(testing_padded,testing_labels_final)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8bNwhcXGiSV"
      },
      "source": [
        "final_eval_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqWBrL93GiSV"
      },
      "source": [
        "trainableParams = np.sum([np.prod(v.get_shape()) for v in model.trainable_weights])\n",
        "trainableParams"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-vGY4VpGiSW"
      },
      "source": [
        "plot_train_eval(history,model_name,trainableParams,optimizer_name,loss,accuracy_metric,epochs,vocab_size,embedding_dim,max_length,trunc_type,oov_tok)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jz2g8oB-GiSX"
      },
      "source": [
        "df=pd.DataFrame([[filename,model_name,model_description,optimizer,loss,accuracy_metric,epochs,vocab_size,embedding_dim,max_length,trunc_type,oov_tok,final_eval_loss,final_eval_acc]],columns=cols)\n",
        "df_metrics=df_metrics.append(df,ignore_index=True)\n",
        "df_metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mX_eeEGrGiSX"
      },
      "source": [
        "model.save(model_name) #save model\n",
        "model=tf.keras.models.load_model(model_name) #load model\n",
        "df_metrics.to_excel('df_metrics.xlsx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CU-IkneGiSY"
      },
      "source": [
        "import io\n",
        "\n",
        "out_v = io.open(f'vecs_{model_name}.tsv', 'w', encoding='utf-8')\n",
        "out_m = io.open(f'meta_{model_name}.tsv', 'w', encoding='utf-8')\n",
        "for word_num in range(1, vocab_size):\n",
        "  word = reverse_word_index[word_num]\n",
        "  embeddings = weights[word_num]\n",
        "  out_m.write(word + \"\\n\")\n",
        "  out_v.write('\\t'.join([str(x) for x in embeddings]) + \"\\n\")\n",
        "out_v.close()\n",
        "out_m.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6G4aH7T-GiSY"
      },
      "source": [
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "  pass\n",
        "else:\n",
        "  files.download(f'vecs_{model_name}.tsv')\n",
        "  files.download(f'meta_{model_name}.tsv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlZsfpzRGiSY"
      },
      "source": [
        "# Testing new Custom Reviews\n",
        "sentence1='What a great movie.'\n",
        "test1=tokenizer.texts_to_sequences([sentence1])\n",
        "test1= pad_sequences(test1, maxlen=max_length, truncating=trunc_type)\n",
        "answer=model.predict(test1)\n",
        "print(f'Review for this sentence: \\n {sentence1} \\n is a value of {answer}')\n",
        "print('This makes sense since it is a value close to 1, meaning a good review')\n",
        "print('\\n')\n",
        "\n",
        "sentence2='What a terrible movie.'\n",
        "test2=tokenizer.texts_to_sequences([sentence2])\n",
        "test2= pad_sequences(test2, maxlen=max_length, truncating=trunc_type)\n",
        "answer=model.predict(test2)\n",
        "print(f'Review for this sentence: \\n {sentence2} \\n is a value of {answer}')\n",
        "print('This makes sense since it is a value close to 0, meaning a bad review')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGZAwqm_HiiX"
      },
      "source": [
        "# 4.5 model5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIjGwAyiHiiX"
      },
      "source": [
        "## Set Embedding/Modeling Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btYxaVoUHiia"
      },
      "source": [
        "filename='TF_CNN_Sequential_NLP_imdb_reviews.ipynb'\n",
        "model_name='model5'\n",
        "optimizer='adam'\n",
        "optimizer_name=str(optimizer)\n",
        "loss='binary_crossentropy'\n",
        "accuracy_metric='binary_accuracy'\n",
        "epochs=10\n",
        "\n",
        "vocab_size = 10000\n",
        "embedding_dim = 16\n",
        "max_length = 120\n",
        "trunc_type='post'\n",
        "oov_tok = '<OOV>'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afN14MiGHiib"
      },
      "source": [
        "## Split Train/Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jW6c6nLBHiib"
      },
      "source": [
        "train_data, test_data = imdb['train'], imdb['test']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2ovdoNXHiic"
      },
      "source": [
        "training_sentences = []\n",
        "training_labels = []\n",
        "\n",
        "testing_sentences = []\n",
        "testing_labels = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnKyJEorHiic"
      },
      "source": [
        "for s, l in train_data:\n",
        "  training_sentences.append(str(s.numpy()))\n",
        "  training_labels.append(l.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dobYL6j0Hiid"
      },
      "source": [
        "for s, l in test_data:\n",
        "  testing_sentences.append(str(s.numpy()))\n",
        "  testing_labels.append(l.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8ceUAvZHiid"
      },
      "source": [
        "import numpy as np\n",
        "training_labels_final = np.array(training_labels)\n",
        "testing_labels_final = np.array(testing_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJr4qsXaHiie"
      },
      "source": [
        "## Create Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OoACPH3RHiie"
      },
      "source": [
        "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok) #create tokenizer that has a vocab_size & oov_token specified above"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHDaTtvoHiie"
      },
      "source": [
        "testing_labels_final.max() #ensure max is still 1 for a \"bad\" review"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZabBFeuHiif"
      },
      "source": [
        "tokenizer.fit_on_texts(training_sentences) #fit the tokenizer on the training_sentences "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCBYtdpyHiif"
      },
      "source": [
        "word_index = tokenizer.word_index #get the word index for the tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzG9y9QKHiif"
      },
      "source": [
        "sequences = tokenizer.texts_to_sequences(training_sentences) #convert texts to sequences using the tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYsUcukAHiif"
      },
      "source": [
        "padded = pad_sequences(sequences, maxlen=max_length, truncating=trunc_type) # pad the sequences by the max_length with truncation set to trunc_type"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvyycltSHiig"
      },
      "source": [
        "testing_sequences = tokenizer.texts_to_sequences(testing_sentences) # convert the testing_sentences to testing_sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzIbzKBiHiig"
      },
      "source": [
        "testing_padded = pad_sequences(testing_sequences, maxlen=max_length) # convert the testing_sequences to testing_padded"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXE1Vfp4Hiig"
      },
      "source": [
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()]) # reverse the key,value from word_index to check index value to key"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9WieVcwHiig"
      },
      "source": [
        "print(decode_review(padded[0])) #This is after it has been padded and OOV in place, but decoded.  Recall this is actually padded as a sequence of numbers for training\n",
        "print(training_sentences[0]) #This is the original"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDj-280VHiih"
      },
      "source": [
        "## Create Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-PxkR5lHiih"
      },
      "source": [
        "model,model_description=model_picker(vocab_size=vocab_size,embedding_dim=embedding_dim,input_length=max_length,model_name='model1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgH6cZ2OHiih"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIDUdk4uHiih"
      },
      "source": [
        "model.compile(loss=loss,optimizer=optimizer,metrics=[accuracy_metric])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZB2h9yjbHiih"
      },
      "source": [
        "## Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noRpJQdoHiii"
      },
      "source": [
        "history=model.fit(padded, training_labels_final,epochs=epochs,validation_data=(testing_padded,\n",
        "                                                                           testing_labels_final))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zp6NJH8fHiii"
      },
      "source": [
        "## Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7R7A39sHiik"
      },
      "source": [
        "e = model.layers[0]\n",
        "weights=e.get_weights()[0]\n",
        "print(weights.shape) # shape: (vocab_size, embedding_dim)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQ3tllvPHiik"
      },
      "source": [
        "final_eval_loss,final_eval_acc=model.evaluate(testing_padded,testing_labels_final)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IsyXvFW7Hiik"
      },
      "source": [
        "final_eval_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHZ_9_xcHiil"
      },
      "source": [
        "trainableParams = np.sum([np.prod(v.get_shape()) for v in model.trainable_weights])\n",
        "trainableParams"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rx8iyrcTHiim"
      },
      "source": [
        "plot_train_eval(history,model_name,trainableParams,optimizer_name,loss,accuracy_metric,epochs,vocab_size,embedding_dim,max_length,trunc_type,oov_tok)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9JH1f-VHiin"
      },
      "source": [
        "df=pd.DataFrame([[filename,model_name,model_description,optimizer,loss,accuracy_metric,epochs,vocab_size,embedding_dim,max_length,trunc_type,oov_tok,final_eval_loss,final_eval_acc]],columns=cols)\n",
        "df_metrics=df_metrics.append(df,ignore_index=True)\n",
        "df_metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_KzC5LZHiin"
      },
      "source": [
        "model.save(model_name) #save model\n",
        "model=tf.keras.models.load_model(model_name) #load model\n",
        "df_metrics.to_excel('df_metrics.xlsx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9_tOc7iHiin"
      },
      "source": [
        "import io\n",
        "\n",
        "out_v = io.open(f'vecs_{model_name}.tsv', 'w', encoding='utf-8')\n",
        "out_m = io.open(f'meta_{model_name}.tsv', 'w', encoding='utf-8')\n",
        "for word_num in range(1, vocab_size):\n",
        "  word = reverse_word_index[word_num]\n",
        "  embeddings = weights[word_num]\n",
        "  out_m.write(word + \"\\n\")\n",
        "  out_v.write('\\t'.join([str(x) for x in embeddings]) + \"\\n\")\n",
        "out_v.close()\n",
        "out_m.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bo9kPFq9Hiin"
      },
      "source": [
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "  pass\n",
        "else:\n",
        "  files.download(f'vecs_{model_name}.tsv')\n",
        "  files.download(f'meta_{model_name}.tsv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6K8I6LAHiin"
      },
      "source": [
        "# Testing new Custom Reviews\n",
        "sentence1='What a great movie.'\n",
        "test1=tokenizer.texts_to_sequences([sentence1])\n",
        "test1= pad_sequences(test1, maxlen=max_length, truncating=trunc_type)\n",
        "answer=model.predict(test1)\n",
        "print(f'Review for this sentence: \\n {sentence1} \\n is a value of {answer}')\n",
        "print('This makes sense since it is a value close to 1, meaning a good review')\n",
        "print('\\n')\n",
        "\n",
        "sentence2='What a terrible movie.'\n",
        "test2=tokenizer.texts_to_sequences([sentence2])\n",
        "test2= pad_sequences(test2, maxlen=max_length, truncating=trunc_type)\n",
        "answer=model.predict(test2)\n",
        "print(f'Review for this sentence: \\n {sentence2} \\n is a value of {answer}')\n",
        "print('This makes sense since it is a value close to 0, meaning a bad review')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9wxRAdWHnaK"
      },
      "source": [
        "# 4.6 model6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sm0_Uv0WHnaL"
      },
      "source": [
        "## Set Embedding/Modeling Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWNt6XL5HnaM"
      },
      "source": [
        "filename='TF_CNN_Sequential_NLP_imdb_reviews.ipynb'\n",
        "model_name='model6'\n",
        "optimizer='adam'\n",
        "optimizer_name=str(optimizer)\n",
        "loss='binary_crossentropy'\n",
        "accuracy_metric='binary_accuracy'\n",
        "epochs=10\n",
        "\n",
        "vocab_size = 10000\n",
        "embedding_dim = 16\n",
        "max_length = 120\n",
        "trunc_type='post'\n",
        "oov_tok = '<OOV>'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6R13Umc1HnaM"
      },
      "source": [
        "## Split Train/Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHhdO9pwHnaM"
      },
      "source": [
        "train_data, test_data = imdb['train'], imdb['test']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aSKfOutHnaM"
      },
      "source": [
        "training_sentences = []\n",
        "training_labels = []\n",
        "\n",
        "testing_sentences = []\n",
        "testing_labels = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXwCUUfWHnaN"
      },
      "source": [
        "for s, l in train_data:\n",
        "  training_sentences.append(str(s.numpy()))\n",
        "  training_labels.append(l.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6sV2xMBHnaN"
      },
      "source": [
        "for s, l in test_data:\n",
        "  testing_sentences.append(str(s.numpy()))\n",
        "  testing_labels.append(l.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6rPH2K5HnaO"
      },
      "source": [
        "import numpy as np\n",
        "training_labels_final = np.array(training_labels)\n",
        "testing_labels_final = np.array(testing_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQ1FmYqJHnaO"
      },
      "source": [
        "## Create Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqZaae2RHnaO"
      },
      "source": [
        "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok) #create tokenizer that has a vocab_size & oov_token specified above"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XBMDOyvHnaO"
      },
      "source": [
        "testing_labels_final.max() #ensure max is still 1 for a \"bad\" review"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsgmrP39HnaP"
      },
      "source": [
        "tokenizer.fit_on_texts(training_sentences) #fit the tokenizer on the training_sentences "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqTGpZBGHnaP"
      },
      "source": [
        "word_index = tokenizer.word_index #get the word index for the tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLcpqgzjHnaP"
      },
      "source": [
        "sequences = tokenizer.texts_to_sequences(training_sentences) #convert texts to sequences using the tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfeWEJymHnaQ"
      },
      "source": [
        "padded = pad_sequences(sequences, maxlen=max_length, truncating=trunc_type) # pad the sequences by the max_length with truncation set to trunc_type"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNnTXQjCHnaQ"
      },
      "source": [
        "testing_sequences = tokenizer.texts_to_sequences(testing_sentences) # convert the testing_sentences to testing_sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWx-nuiPHnaR"
      },
      "source": [
        "testing_padded = pad_sequences(testing_sequences, maxlen=max_length) # convert the testing_sequences to testing_padded"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5HG-ku8HnaR"
      },
      "source": [
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()]) # reverse the key,value from word_index to check index value to key"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrmsX-mUHnaS"
      },
      "source": [
        "print(decode_review(padded[0])) #This is after it has been padded and OOV in place, but decoded.  Recall this is actually padded as a sequence of numbers for training\n",
        "print(training_sentences[0]) #This is the original"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLv9FMYcHnaS"
      },
      "source": [
        "## Create Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4e5_NsxHnaS"
      },
      "source": [
        "model,model_description=model_picker(vocab_size=vocab_size,embedding_dim=embedding_dim,input_length=max_length,model_name='model1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmpWRT7HHnaS"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "am1W75XpHnaU"
      },
      "source": [
        "model.compile(loss=loss,optimizer=optimizer,metrics=[accuracy_metric])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVFY3gQdHnaV"
      },
      "source": [
        "## Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUWw-0IfHnaW"
      },
      "source": [
        "history=model.fit(padded, training_labels_final,epochs=epochs,validation_data=(testing_padded,\n",
        "                                                                           testing_labels_final))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogx-EljWHnaX"
      },
      "source": [
        "## Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-w2Vk6cHnaX"
      },
      "source": [
        "e = model.layers[0]\n",
        "weights=e.get_weights()[0]\n",
        "print(weights.shape) # shape: (vocab_size, embedding_dim)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abVinIDnHnaX"
      },
      "source": [
        "final_eval_loss,final_eval_acc=model.evaluate(testing_padded,testing_labels_final)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85LHQMCHHnaY"
      },
      "source": [
        "final_eval_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtH0qxbtHnaY"
      },
      "source": [
        "trainableParams = np.sum([np.prod(v.get_shape()) for v in model.trainable_weights])\n",
        "trainableParams"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hP1tasbjHnaY"
      },
      "source": [
        "plot_train_eval(history,model_name,trainableParams,optimizer_name,loss,accuracy_metric,epochs,vocab_size,embedding_dim,max_length,trunc_type,oov_tok)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8NnOQGzHnaZ"
      },
      "source": [
        "df=pd.DataFrame([[filename,model_name,model_description,optimizer,loss,accuracy_metric,epochs,vocab_size,embedding_dim,max_length,trunc_type,oov_tok,final_eval_loss,final_eval_acc]],columns=cols)\n",
        "df_metrics=df_metrics.append(df,ignore_index=True)\n",
        "df_metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCRSbsg_HnaZ"
      },
      "source": [
        "model.save(model_name) #save model\n",
        "model=tf.keras.models.load_model(model_name) #load model\n",
        "df_metrics.to_excel('df_metrics.xlsx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fO_zdoHHnaa"
      },
      "source": [
        "import io\n",
        "\n",
        "out_v = io.open(f'vecs_{model_name}.tsv', 'w', encoding='utf-8')\n",
        "out_m = io.open(f'meta_{model_name}.tsv', 'w', encoding='utf-8')\n",
        "for word_num in range(1, vocab_size):\n",
        "  word = reverse_word_index[word_num]\n",
        "  embeddings = weights[word_num]\n",
        "  out_m.write(word + \"\\n\")\n",
        "  out_v.write('\\t'.join([str(x) for x in embeddings]) + \"\\n\")\n",
        "out_v.close()\n",
        "out_m.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwC4VWDaHnaa"
      },
      "source": [
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "  pass\n",
        "else:\n",
        "  files.download(f'vecs_{model_name}.tsv')\n",
        "  files.download(f'meta_{model_name}.tsv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pvkl7xscHnaa"
      },
      "source": [
        "# Testing new Custom Reviews\n",
        "sentence1='What a great movie.'\n",
        "test1=tokenizer.texts_to_sequences([sentence1])\n",
        "test1= pad_sequences(test1, maxlen=max_length, truncating=trunc_type)\n",
        "answer=model.predict(test1)\n",
        "print(f'Review for this sentence: \\n {sentence1} \\n is a value of {answer}')\n",
        "print('This makes sense since it is a value close to 1, meaning a good review')\n",
        "print('\\n')\n",
        "\n",
        "sentence2='What a terrible movie.'\n",
        "test2=tokenizer.texts_to_sequences([sentence2])\n",
        "test2= pad_sequences(test2, maxlen=max_length, truncating=trunc_type)\n",
        "answer=model.predict(test2)\n",
        "print(f'Review for this sentence: \\n {sentence2} \\n is a value of {answer}')\n",
        "print('This makes sense since it is a value close to 0, meaning a bad review')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LuUpVgsyIhR5"
      },
      "source": [
        "# 4.7 model7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkB6KINKIhR_"
      },
      "source": [
        "## Set Embedding/Modeling Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3s2hyLTIhSA"
      },
      "source": [
        "filename='TF_CNN_Sequential_NLP_imdb_reviews.ipynb'\n",
        "model_name='model7'\n",
        "optimizer='adam'\n",
        "optimizer_name=str(optimizer)\n",
        "loss='binary_crossentropy'\n",
        "accuracy_metric='binary_accuracy'\n",
        "epochs=10\n",
        "\n",
        "vocab_size = 10000\n",
        "embedding_dim = 16\n",
        "max_length = 120\n",
        "trunc_type='post'\n",
        "oov_tok = '<OOV>'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_IQZ9rnoIhSC"
      },
      "source": [
        "## Split Train/Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXEozv1gIhSD"
      },
      "source": [
        "train_data, test_data = imdb['train'], imdb['test']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7JkBst4IhSE"
      },
      "source": [
        "training_sentences = []\n",
        "training_labels = []\n",
        "\n",
        "testing_sentences = []\n",
        "testing_labels = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puXeewnBIhSF"
      },
      "source": [
        "for s, l in train_data:\n",
        "  training_sentences.append(str(s.numpy()))\n",
        "  training_labels.append(l.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d06J9cVuIhSI"
      },
      "source": [
        "for s, l in test_data:\n",
        "  testing_sentences.append(str(s.numpy()))\n",
        "  testing_labels.append(l.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D99HwnprIhSJ"
      },
      "source": [
        "import numpy as np\n",
        "training_labels_final = np.array(training_labels)\n",
        "testing_labels_final = np.array(testing_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ask1o64IhSJ"
      },
      "source": [
        "## Create Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZHM0T4ZIhSK"
      },
      "source": [
        "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok) #create tokenizer that has a vocab_size & oov_token specified above"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjFcuaEKIhSN"
      },
      "source": [
        "testing_labels_final.max() #ensure max is still 1 for a \"bad\" review"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RFjeAq2IhSN"
      },
      "source": [
        "tokenizer.fit_on_texts(training_sentences) #fit the tokenizer on the training_sentences "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RbNh3vMIhSP"
      },
      "source": [
        "word_index = tokenizer.word_index #get the word index for the tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCPYAW3vIhSP"
      },
      "source": [
        "sequences = tokenizer.texts_to_sequences(training_sentences) #convert texts to sequences using the tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPwEu0i2IhSP"
      },
      "source": [
        "padded = pad_sequences(sequences, maxlen=max_length, truncating=trunc_type) # pad the sequences by the max_length with truncation set to trunc_type"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzcxzVQAIhSP"
      },
      "source": [
        "testing_sequences = tokenizer.texts_to_sequences(testing_sentences) # convert the testing_sentences to testing_sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A94_QB1OIhSQ"
      },
      "source": [
        "testing_padded = pad_sequences(testing_sequences, maxlen=max_length) # convert the testing_sequences to testing_padded"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnlMBd7oIhSR"
      },
      "source": [
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()]) # reverse the key,value from word_index to check index value to key"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gExl74NLIhSS"
      },
      "source": [
        "print(decode_review(padded[0])) #This is after it has been padded and OOV in place, but decoded.  Recall this is actually padded as a sequence of numbers for training\n",
        "print(training_sentences[0]) #This is the original"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96j-5N2bIhST"
      },
      "source": [
        "## Create Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIL5AxazIhSU"
      },
      "source": [
        "model,model_description=model_picker(vocab_size=vocab_size,embedding_dim=embedding_dim,input_length=max_length,model_name='model1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxErMDJzIhSU"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1l3Oz5vWIhSU"
      },
      "source": [
        "model.compile(loss=loss,optimizer=optimizer,metrics=[accuracy_metric])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6-khjByIhSU"
      },
      "source": [
        "## Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s63jyBpQIhSV"
      },
      "source": [
        "history=model.fit(padded, training_labels_final,epochs=epochs,validation_data=(testing_padded,\n",
        "                                                                           testing_labels_final))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSMEJ7CvIhSW"
      },
      "source": [
        "## Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0NVCAyrIhSY"
      },
      "source": [
        "e = model.layers[0]\n",
        "weights=e.get_weights()[0]\n",
        "print(weights.shape) # shape: (vocab_size, embedding_dim)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixPMMlYLIhSZ"
      },
      "source": [
        "final_eval_loss,final_eval_acc=model.evaluate(testing_padded,testing_labels_final)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFB2COf1IhSZ"
      },
      "source": [
        "final_eval_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcKU9BQjIhSZ"
      },
      "source": [
        "trainableParams = np.sum([np.prod(v.get_shape()) for v in model.trainable_weights])\n",
        "trainableParams"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhwaeV2aIhSa"
      },
      "source": [
        "plot_train_eval(history,model_name,trainableParams,optimizer_name,loss,accuracy_metric,epochs,vocab_size,embedding_dim,max_length,trunc_type,oov_tok)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pws22ekKIhSb"
      },
      "source": [
        "df=pd.DataFrame([[filename,model_name,model_description,optimizer,loss,accuracy_metric,epochs,vocab_size,embedding_dim,max_length,trunc_type,oov_tok,final_eval_loss,final_eval_acc]],columns=cols)\n",
        "df_metrics=df_metrics.append(df,ignore_index=True)\n",
        "df_metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTFcm8qXIhSb"
      },
      "source": [
        "model.save(model_name) #save model\n",
        "model=tf.keras.models.load_model(model_name) #load model\n",
        "df_metrics.to_excel('df_metrics.xlsx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xn8KBEbhIhSc"
      },
      "source": [
        "import io\n",
        "\n",
        "out_v = io.open(f'vecs_{model_name}.tsv', 'w', encoding='utf-8')\n",
        "out_m = io.open(f'meta_{model_name}.tsv', 'w', encoding='utf-8')\n",
        "for word_num in range(1, vocab_size):\n",
        "  word = reverse_word_index[word_num]\n",
        "  embeddings = weights[word_num]\n",
        "  out_m.write(word + \"\\n\")\n",
        "  out_v.write('\\t'.join([str(x) for x in embeddings]) + \"\\n\")\n",
        "out_v.close()\n",
        "out_m.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIJzPBhOIhSd"
      },
      "source": [
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "  pass\n",
        "else:\n",
        "  files.download(f'vecs_{model_name}.tsv')\n",
        "  files.download(f'meta_{model_name}.tsv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqHvim9tIhSd"
      },
      "source": [
        "# Testing new Custom Reviews\n",
        "sentence1='What a great movie.'\n",
        "test1=tokenizer.texts_to_sequences([sentence1])\n",
        "test1= pad_sequences(test1, maxlen=max_length, truncating=trunc_type)\n",
        "answer=model.predict(test1)\n",
        "print(f'Review for this sentence: \\n {sentence1} \\n is a value of {answer}')\n",
        "print('This makes sense since it is a value close to 1, meaning a good review')\n",
        "print('\\n')\n",
        "\n",
        "sentence2='What a terrible movie.'\n",
        "test2=tokenizer.texts_to_sequences([sentence2])\n",
        "test2= pad_sequences(test2, maxlen=max_length, truncating=trunc_type)\n",
        "answer=model.predict(test2)\n",
        "print(f'Review for this sentence: \\n {sentence2} \\n is a value of {answer}')\n",
        "print('This makes sense since it is a value close to 0, meaning a bad review')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5WiW8GoCTP5"
      },
      "source": [
        "# 5.0 Export Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IivQI5d-qcJX"
      },
      "source": [
        "!zip -r /content/model1.zip /content/model1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--Y8u5jeAmfC"
      },
      "source": [
        "!zip -r /content/model2.zip /content/model2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OojcA5ovAoZy"
      },
      "source": [
        "!zip -r /content/model3.zip /content/model3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flLhsLK4GpKP"
      },
      "source": [
        "!zip -r /content/model4.zip /content/model4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGxkqtm2JT-3"
      },
      "source": [
        "!zip -r /content/model5.zip /content/model5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y34JPnOfJV8a"
      },
      "source": [
        "!zip -r /content/model6.zip /content/model6"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9EBKr3aJYPr"
      },
      "source": [
        "!zip -r /content/model7.zip /content/model7"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbIbIOWJD0z3"
      },
      "source": [
        "# Install **rclone**\n",
        "This is so you can save your checkpoints weights to your actual google drive for restoration."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JZkhNVByOq-"
      },
      "source": [
        "! curl https://rclone.org/install.sh | sudo bash"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCgqY-B7EJxi"
      },
      "source": [
        "You want to create a remote configuration with rclone.  Use the default recommendations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gOec5AkyF-L"
      },
      "source": [
        "!rclone config"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2a96jdVeEZiy"
      },
      "source": [
        "# Copy Content to **Google Drive** with **rclone**\n",
        "Try to copy exisiting weights to a future directory to ensure rclone is configured right"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIjidiznFvJ3"
      },
      "source": [
        "This line tests the ability to copy known weights to a directory on you **Google Drive** with **rclone**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "220dIpBS_zBv"
      },
      "source": [
        "!rclone copy \"/content/\"  remote:\"/Colab_Notebooks/GitHub/TensorFlow_Examples/Basics/Wk6/content\""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}