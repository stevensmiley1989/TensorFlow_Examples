{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stevensmiley1989/TensorFlow_Examples/blob/main/C2_W4_Lab_2_multi_GPU_mirrored_strategy_with_CUSTOM_TFLITE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2-nIvppiQ4C"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/https-deeplearning-ai/tensorflow-3-public/blob/main/Course%202%20-%20Custom%20Training%20loops%2C%20Gradients%20and%20Distributed%20Training/Week%204%20-%20Distribution%20Strategy/C2_W4_Lab_2_multi-GPU-mirrored-strategy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydiHeIUCiQ4H"
      },
      "source": [
        "# Multi-GPU Mirrored Strategy\n",
        "\n",
        "In this ungraded lab, you'll go through how to set up a Multi-GPU Mirrored Strategy. The lab environment only has a CPU but we placed the code here in case you want to try this out for yourself in a multiGPU device.\n",
        "\n",
        "**Notes:** \n",
        "- If you are running this on Coursera, you'll see it gives a warning about no presence of GPU devices. \n",
        "- If you are running this in Colab, make sure you have selected your `runtime` to be `GPU`. \n",
        "- In both these cases, you'll see there's only 1 device that is available.  \n",
        "- One device is sufficient for helping you understand these distribution strategies."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5VMl1jcviQ4K"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z0IHEff-iQ4N"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izH4WZefiQ4O"
      },
      "source": [
        "## Setup Distribution Strategy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpfkBBHdiQ4O",
        "outputId": "2b5d9915-8525-4eff-8c8c-903f61b20f5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "Number of devices: 1\n"
          ]
        }
      ],
      "source": [
        "# Note that it generally has a minimum of 8 cores, but if your GPU has\n",
        "# less, you need to set this. In this case one of my GPUs has 4 cores\n",
        "os.environ[\"TF_MIN_GPU_MULTIPROCESSOR_COUNT\"] = \"4\"\n",
        "\n",
        "# If the list of devices is not specified in the\n",
        "# `tf.distribute.MirroredStrategy` constructor, it will be auto-detected.\n",
        "# If you have *different* GPUs in your system, you probably have to set up cross_device_ops like this\n",
        "strategy = tf.distribute.MirroredStrategy(cross_device_ops=tf.distribute.HierarchicalCopyAllReduce())\n",
        "print ('Number of devices: {}'.format(strategy.num_replicas_in_sync))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwnOsFw9iQ4P"
      },
      "source": [
        "## Prepare the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2vNHiZMiQ4Q",
        "outputId": "4f6a4c3b-8f11-471d-9e64-da8153e09ee4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# Get the data\n",
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "\n",
        "# Adding a dimension to the array -> new shape == (28, 28, 1)\n",
        "# We are doing this because the first layer in our model is a convolutional\n",
        "# layer and it requires a 4D input (batch_size, height, width, channels).\n",
        "# batch_size dimension will be added later on.\n",
        "train_images = train_images[..., None]\n",
        "test_images = test_images[..., None]\n",
        "\n",
        "# Normalize the images to [0, 1] range.\n",
        "train_images = train_images / np.float32(255)\n",
        "test_images = test_images / np.float32(255)\n",
        "\n",
        "\n",
        "# Batch the input data\n",
        "BUFFER_SIZE = len(train_images)\n",
        "BATCH_SIZE_PER_REPLICA = 64\n",
        "GLOBAL_BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\n",
        "\n",
        "# Create Datasets from the batches\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels)).shuffle(BUFFER_SIZE).batch(GLOBAL_BATCH_SIZE)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).batch(GLOBAL_BATCH_SIZE)\n",
        "\n",
        "# Create Distributed Datasets from the datasets\n",
        "train_dist_dataset = strategy.experimental_distribute_dataset(train_dataset)\n",
        "test_dist_dataset = strategy.experimental_distribute_dataset(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BVPOogt_GvLV"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zg_uDYDviQ4T"
      },
      "source": [
        "## Define the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EV639zxniQ4U"
      },
      "outputs": [],
      "source": [
        "# Create the model architecture\n",
        "def create_model():\n",
        "  model = tf.keras.Sequential([\n",
        "      tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
        "      tf.keras.layers.AveragePooling2D(),\n",
        "      tf.keras.layers.Conv2D(64, 3, activation='relu'),\n",
        "      tf.keras.layers.AveragePooling2D(),\n",
        "      tf.keras.layers.Flatten(),\n",
        "      tf.keras.layers.Dense(64, activation='relu'),\n",
        "      tf.keras.layers.Dense(10)\n",
        "    ])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HyzHlGbKiQ4W"
      },
      "source": [
        "## Configure custom training\n",
        "\n",
        "Instead of `model.compile()`, we're going to do custom training, so let's do that within a strategy scope."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jvxd4hI1iQ4Y",
        "outputId": "00dcf42f-5244-4234-843f-4d5a0951d22a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ]
        }
      ],
      "source": [
        "with strategy.scope():\n",
        "    # We will use sparse categorical crossentropy as always. But, instead of having the loss function\n",
        "    # manage the map reduce across GPUs for us, we'll do it ourselves with a simple algorithm.\n",
        "    # Remember -- the map reduce is how the losses get aggregated\n",
        "    # Set reduction to `none` so we can do the reduction afterwards and divide byglobal batch size.\n",
        "    loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.NONE)\n",
        "\n",
        "    def compute_loss(labels, predictions):\n",
        "        # Compute Loss uses the loss object to compute the loss\n",
        "        # Notice that per_example_loss will have an entry per GPU\n",
        "        # so in this case there'll be 2 -- i.e. the loss for each replica\n",
        "        per_example_loss = loss_object(labels, predictions)\n",
        "\n",
        "        # You can print it to see it -- you'll get output like this:\n",
        "        # Tensor(\"sparse_categorical_crossentropy/weighted_loss/Mul:0\", shape=(48,), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\n",
        "        # Tensor(\"replica_1/sparse_categorical_crossentropy/weighted_loss/Mul:0\", shape=(48,), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:1)\n",
        "        # Note in particular that replica_0 isn't named in the weighted_loss -- the first is unnamed, the second is replica_1 etc\n",
        "        print(per_example_loss)\n",
        "        return tf.nn.compute_average_loss(per_example_loss, global_batch_size=GLOBAL_BATCH_SIZE)\n",
        "\n",
        "    # We'll just reduce by getting the average of the losses\n",
        "    test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
        "\n",
        "    # Accuracy on train and test will be SparseCategoricalAccuracy\n",
        "    train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
        "    test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')\n",
        "\n",
        "    # Optimizer will be Adam\n",
        "    optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "    # Create the model within the scope\n",
        "    model = create_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Cx7w0KWiQ4a"
      },
      "source": [
        "## Train and Test Steps Functions\n",
        "\n",
        "Let's define a few utilities to facilitate the training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k0VOdqKP2NEz"
      },
      "outputs": [],
      "source": [
        "# `run` replicates the provided computation and runs it\n",
        "# with the distributed input.\n",
        "@tf.function\n",
        "def distributed_train_step(dataset_inputs):\n",
        "  per_replica_losses = strategy.run(train_step, args=(dataset_inputs,))\n",
        "  #tf.print(per_replica_losses.values)\n",
        "  return strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses, axis=None)\n",
        "\n",
        "def train_step(inputs):\n",
        "  images, labels = inputs\n",
        "  with tf.GradientTape() as tape:\n",
        "    predictions = model(images, training=True)\n",
        "    loss = compute_loss(labels, predictions)\n",
        "\n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "  train_accuracy.update_state(labels, predictions)\n",
        "  return loss\n",
        "\n",
        "#######################\n",
        "# Test Steps Functions\n",
        "#######################\n",
        "@tf.function\n",
        "def distributed_test_step(dataset_inputs):\n",
        "  return strategy.run(test_step, args=(dataset_inputs,))\n",
        "\n",
        "def test_step(inputs):\n",
        "  images, labels = inputs\n",
        "\n",
        "  predictions = model(images, training=False)\n",
        "  t_loss = loss_object(labels, predictions)\n",
        "\n",
        "  test_loss.update_state(t_loss)\n",
        "  test_accuracy.update_state(labels, predictions)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfJTBnILiQ4b"
      },
      "source": [
        "## Training Loop\n",
        "\n",
        "We can now start training the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYWsnkfOiQ4c",
        "outputId": "b74934ff-b8a7-4300-bf9f-d65ed1f04220"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tensor(\"sparse_categorical_crossentropy/weighted_loss/Mul:0\", shape=(64,), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)\n",
            "Tensor(\"sparse_categorical_crossentropy/weighted_loss/Mul:0\", shape=(64,), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)\n",
            "Tensor(\"sparse_categorical_crossentropy/weighted_loss/Mul:0\", shape=(32,), dtype=float32, device=/job:localhost/replica:0/task:0/device:CPU:0)\n",
            "Epoch 1, Loss: 0.5716544389724731, Accuracy: 79.24833679199219, Test Loss: 0.44839048385620117, Test Accuracy: 84.05000305175781\n",
            "Epoch 2, Loss: 0.39026057720184326, Accuracy: 85.81832885742188, Test Loss: 0.40717411041259766, Test Accuracy: 84.55999755859375\n",
            "Epoch 3, Loss: 0.340708464384079, Accuracy: 87.6883316040039, Test Loss: 0.3862076699733734, Test Accuracy: 85.63999938964844\n",
            "Epoch 4, Loss: 0.307722270488739, Accuracy: 88.86499786376953, Test Loss: 0.35899293422698975, Test Accuracy: 86.3699951171875\n",
            "Epoch 5, Loss: 0.28488653898239136, Accuracy: 89.67000579833984, Test Loss: 0.29829347133636475, Test Accuracy: 89.20000457763672\n",
            "Epoch 6, Loss: 0.2637885808944702, Accuracy: 90.2633285522461, Test Loss: 0.29473528265953064, Test Accuracy: 89.4800033569336\n",
            "Epoch 7, Loss: 0.24777163565158844, Accuracy: 90.9866714477539, Test Loss: 0.27655136585235596, Test Accuracy: 90.11000061035156\n",
            "Epoch 8, Loss: 0.23355041444301605, Accuracy: 91.44833374023438, Test Loss: 0.26792967319488525, Test Accuracy: 90.24000549316406\n",
            "Epoch 9, Loss: 0.22060684859752655, Accuracy: 91.86166381835938, Test Loss: 0.26588526368141174, Test Accuracy: 90.43000030517578\n",
            "Epoch 10, Loss: 0.21112088859081268, Accuracy: 92.19499969482422, Test Loss: 0.25624343752861023, Test Accuracy: 90.73999786376953\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 10\n",
        "for epoch in range(EPOCHS):\n",
        "  # Do Training\n",
        "  total_loss = 0.0\n",
        "  num_batches = 0\n",
        "  for batch in train_dist_dataset:\n",
        "    total_loss += distributed_train_step(batch)\n",
        "    num_batches += 1\n",
        "  train_loss = total_loss / num_batches\n",
        "\n",
        "  # Do Testing\n",
        "  for batch in test_dist_dataset:\n",
        "    distributed_test_step(batch)\n",
        "\n",
        "  template = (\"Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, \" \"Test Accuracy: {}\")\n",
        "\n",
        "  print (template.format(epoch+1, train_loss, train_accuracy.result()*100, test_loss.result(), test_accuracy.result()*100))\n",
        "\n",
        "  test_loss.reset_states()\n",
        "  train_accuracy.reset_states()\n",
        "  test_accuracy.reset_states()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "rYT9-crkWzv_"
      },
      "outputs": [],
      "source": [
        "import cv2,matplotlib.pyplot as plt\n",
        "fimage=train_images[0:10]\n",
        "\n",
        "\n",
        "def representative_data_gen(fimage=train_images[0:10]):\n",
        "  #fimage=train_images[0:10]\n",
        "  for input_value in range(10):\n",
        "    if input_value in range(10):\n",
        "      image_data=fimage[input_value]\n",
        "      img_in = image_data[np.newaxis, ...].astype(np.float32)\n",
        "      #print(\"calibration image {}\".format(fimage[input_value]))\n",
        "      yield [img_in]\n",
        "    else:\n",
        "      continue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ec9D2jS5qeb",
        "outputId": "39087b52-70e0-4bb2-c2de-e7b5a2682b7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: tmpdir/module_no_signatures/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: tmpdir/module_no_signatures/assets\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "tmpdir='tmpdir'\n",
        "try:\n",
        "  os.mkdir(tmpdir)\n",
        "except:\n",
        "  pass\n",
        "custom_save_path = os.path.join(tmpdir, \"module_no_signatures\")\n",
        "tf.saved_model.save(model, custom_save_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmMoo6jb3q9U",
        "outputId": "2eeb9889-542e-4de4-fc74-5a593f808df6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Convert the model\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(custom_save_path) # path to the SavedModel directory\n",
        "\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\n",
        "converter.allow_custom_ops = True\n",
        "converter.representative_dataset = representative_data_gen\n",
        "\n",
        "tflite_model = converter.convert()\n",
        "# Save the model.\n",
        "with open('model.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMWnMMe66ssA",
        "outputId": "d31d8562-59b4-4784-ef55-4015d3bd23be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  2537  100  2537    0     0  79281      0 --:--:-- --:--:-- --:--:-- 81838\n",
            "OK\n",
            "deb https://packages.cloud.google.com/apt coral-edgetpu-stable main\n",
            "Hit:1 https://packages.cloud.google.com/apt coral-edgetpu-stable InRelease\n",
            "Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:3 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "Ign:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:7 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Hit:9 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Hit:10 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:13 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:14 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,242 kB]\n",
            "Hit:17 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Fetched 2,494 kB in 2s (1,266 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "edgetpu-compiler is already the newest version (16.0).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 64 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -\n",
        "\n",
        "!echo \"deb https://packages.cloud.google.com/apt coral-edgetpu-stable main\" | sudo tee /etc/apt/sources.list.d/coral-edgetpu.list\n",
        "\n",
        "!sudo apt-get update\n",
        "\n",
        "!sudo apt-get install edgetpu-compiler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQNnUxCb7Mz7",
        "outputId": "479ad25e-96a3-4dd7-d7ba-e18b8facccf7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Edge TPU Compiler version 16.0.384591198\n",
            "Started a compilation timeout timer of 180 seconds.\n",
            "\n",
            "Model compiled successfully in 111 ms.\n",
            "\n",
            "Input model: model.tflite\n",
            "Input size: 125.44KiB\n",
            "Output model: model_edgetpu.tflite\n",
            "Output size: 200.91KiB\n",
            "On-chip memory used for caching model parameters: 126.25KiB\n",
            "On-chip memory remaining for caching model parameters: 7.62MiB\n",
            "Off-chip memory used for streaming uncached model parameters: 0.00B\n",
            "Number of Edge TPU subgraphs: 1\n",
            "Total number of operations: 9\n",
            "Operation log: model_edgetpu.log\n",
            "\n",
            "Model successfully compiled but not all operations are supported by the Edge TPU. A percentage of the model will instead run on the CPU, which is slower. If possible, consider updating your model to use only operations supported by the Edge TPU. For details, visit g.co/coral/model-reqs.\n",
            "Number of operations that will run on Edge TPU: 7\n",
            "Number of operations that will run on CPU: 2\n",
            "See the operation log file for individual operation details.\n",
            "Compilation child process completed within timeout period.\n",
            "Compilation succeeded! \n"
          ]
        }
      ],
      "source": [
        "!edgetpu_compiler model.tflite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Qs43wa9a7Xv9"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "C2_W4_Lab_2_multi-GPU-mirrored-strategy_with_CUSTOM_TFLITE.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}